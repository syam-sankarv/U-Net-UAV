{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa78e12f-8b4d-47d4-9c27-7a83f2a7086f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input\n",
    "from tensorflow.keras.utils import img_to_array, load_img\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from sklearn.metrics import precision_score, f1_score, confusion_matrix\n",
    "from tensorflow.keras.layers import Conv2D, GlobalAveragePooling2D, Reshape, MaxPooling2D, UpSampling2D, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define image dimensions and channels\n",
    "IMG_HEIGHT = 512\n",
    "IMG_WIDTH = 512\n",
    "IMG_CHANNELS = 3\n",
    "input_shape = (IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "num_classes = 1  # Single class segmentation\n",
    "\n",
    "train_image_dir = '/home/syam.varnatt/THESIS/images/train/images'\n",
    "train_mask_dir = '/home/syam.varnatt/THESIS/images/train/masks'\n",
    "val_image_dir = '/home/syam.varnatt/THESIS/images/val/images'\n",
    "val_mask_dir = '/home/syam.varnatt/THESIS/images/val/masks'\n",
    "SAVE_DIRECTORY = '/home/syam.varnatt/THESIS/comparison-model/unet/no-aug/results'\n",
    "\n",
    "def load_dataset(image_dir, mask_dir, img_size):\n",
    "    images = []\n",
    "    masks = []\n",
    "    \n",
    "    for image_name in tqdm(os.listdir(image_dir)):\n",
    "        if image_name.lower().endswith(('.jpeg', '.jpg')):\n",
    "            base_name = os.path.splitext(image_name)[0]\n",
    "            mask_name = f\"{base_name}_mask.jpg\"\n",
    "            \n",
    "            img_path = os.path.join(image_dir, image_name)\n",
    "            mask_path = os.path.join(mask_dir, mask_name)\n",
    "            \n",
    "            if os.path.exists(img_path) and os.path.exists(mask_path):\n",
    "                try:\n",
    "                    image = load_img(img_path, target_size=img_size)\n",
    "                    mask = load_img(mask_path, target_size=img_size, color_mode=\"grayscale\")\n",
    "                    \n",
    "                    image = img_to_array(image)\n",
    "                    mask = img_to_array(mask)\n",
    "                    \n",
    "                    images.append(image)\n",
    "                    masks.append(mask)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {image_name}: {e}\")\n",
    "            else:\n",
    "                print(f\"Mask not found for image: {image_name}\")\n",
    "    \n",
    "    images = np.array(images) / 255.0\n",
    "    masks = np.array(masks) / 255.0\n",
    "    masks = (masks > 0.5).astype(np.uint8)\n",
    "    \n",
    "    return images, masks\n",
    "\n",
    "# Load datasets\n",
    "train_images, train_masks = load_dataset(train_image_dir, train_mask_dir, (IMG_HEIGHT, IMG_WIDTH))\n",
    "print(\"Training dataset loaded completely\")\n",
    "val_images, val_masks = load_dataset(val_image_dir, val_mask_dir, (IMG_HEIGHT, IMG_WIDTH))\n",
    "print(\"Validation dataset loaded completely\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0647f754-ff37-4bf1-9cc2-a11e0c5410d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet(input_size=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)):\n",
    "    inputs = Input(input_size)\n",
    "\n",
    "    # Contraction path\n",
    "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
    "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
    "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n",
    "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "\n",
    "    # Bottleneck\n",
    "    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)\n",
    "    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)\n",
    "\n",
    "    # Expansive path\n",
    "    u6 = UpSampling2D((2, 2))(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n",
    "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n",
    "\n",
    "    u7 = UpSampling2D((2, 2))(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n",
    "    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n",
    "\n",
    "    u8 = UpSampling2D((2, 2))(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n",
    "    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n",
    "\n",
    "    u9 = UpSampling2D((2, 2))(c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n",
    "    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n",
    "\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Initiate the U-Net model\n",
    "model = unet()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a06141-296f-412c-b4b9-5e30f02103d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualizationCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, val_images, val_masks, save_dir, num_samples=3):\n",
    "        super(VisualizationCallback, self).__init__()\n",
    "        self.val_images = val_images\n",
    "        self.val_masks = val_masks\n",
    "        self.save_dir = save_dir\n",
    "        self.num_samples = num_samples  # Number of samples to visualize per epoch\n",
    "        os.makedirs(save_dir, exist_ok=True)  # Ensure the save directory exists\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Randomly select a few samples to visualize predictions\n",
    "        idxs = np.random.choice(len(self.val_images), self.num_samples, replace=False)\n",
    "        images_to_show = self.val_images[idxs]\n",
    "        masks_to_show = self.val_masks[idxs]\n",
    "        \n",
    "        # Use the model attribute directly, which is set automatically by Keras\n",
    "        predictions = self.model.predict(images_to_show)\n",
    "\n",
    "        # Plot and save the images, masks, and predictions\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        for i in range(self.num_samples):\n",
    "            plt.subplot(self.num_samples, 3, i * 3 + 1)\n",
    "            plt.imshow(images_to_show[i])\n",
    "            plt.title(f'Input Image {i+1}')\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.subplot(self.num_samples, 3, i * 3 + 2)\n",
    "            plt.imshow(masks_to_show[i].squeeze(), cmap='gray')\n",
    "            plt.title(f'True Mask {i+1}')\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.subplot(self.num_samples, 3, i * 3 + 3)\n",
    "            plt.imshow(predictions[i].squeeze(), cmap='gray')\n",
    "            plt.title(f'Predicted Mask {i+1}')\n",
    "            plt.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        # Save the plot to file\n",
    "        plt.savefig(os.path.join(self.save_dir, f'epoch_{epoch+1:02d}_predictions.png'))\n",
    "        plt.close()\n",
    "        print(f\"Saved visualization for epoch {epoch+1}.\")\n",
    "\n",
    "# Instantiate the visualization callback\n",
    "visualization_callback = VisualizationCallback(val_images, val_masks, SAVE_DIRECTORY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d98fc81-4897-4abc-8767-6ba2c9914823",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingTimeCallback(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.start_time = time.time()\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        end_time = time.time()\n",
    "        training_time = end_time - self.start_time\n",
    "        print(f\"Training Time: {training_time / 60:.2f} minutes\")\n",
    "\n",
    "# Create an instance of the callback\n",
    "training_time_callback = TrainingTimeCallback()\n",
    "\n",
    "# Define callbacks\n",
    "checkpoint = ModelCheckpoint('unet_model.keras', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_images, train_masks,\n",
    "    validation_data=(val_images, val_masks),\n",
    "    batch_size=8,\n",
    "    epochs=100,\n",
    "    callbacks=[checkpoint, early_stopping, training_time_callback, visualization_callback]\n",
    ")\n",
    "\n",
    "# Save the training history to an Excel file\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.to_excel(os.path.join('training_history.xlsx'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b0d738-0789-4fd3-ae15-a8265239f156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model saved so far\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('/home/syam.varnatt/THESIS/comparison-model/unet/no-aug/unet_model.keras')\n",
    "\n",
    "# Continue training from the previous state\n",
    "# Adjust the number of epochs based on how many more epochs are desired\n",
    "new_epochs = 50  # Set the additional number of epochs\n",
    "\n",
    "# Define the same callbacks\n",
    "checkpoint = ModelCheckpoint('unet_model.keras', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min')\n",
    "\n",
    "# Continue training\n",
    "history = model.fit(\n",
    "    train_images, train_masks,\n",
    "    validation_data=(val_images, val_masks),\n",
    "    batch_size=8,\n",
    "    epochs=100 + new_epochs,  # Total number of epochs after resuming\n",
    "    initial_epoch=100,  # Start from the last epoch trained (100 in your case)\n",
    "    callbacks=[checkpoint, early_stopping, training_time_callback, visualization_callback]\n",
    ")\n",
    "\n",
    "# Optionally, save the updated training history to a new Excel file\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.to_excel(os.path.join('continued_training_history.xlsx'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1275c1a9-d03a-4be9-a656-e3a2865b3ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predict on validation set\n",
    "val_preds = model.predict(val_images)\n",
    "\n",
    "# Convert predictions to binary\n",
    "val_preds_bin = (val_preds > 0.3).astype(int)\n",
    "\n",
    "# Calculate additional metrics\n",
    "precision = precision_score(val_masks.flatten(), val_preds_bin.flatten())\n",
    "f1 = f1_score(val_masks.flatten(), val_preds_bin.flatten())\n",
    "\n",
    "# Calculate Mean IoU\n",
    "mean_iou_metric = tf.keras.metrics.MeanIoU(num_classes=2) \n",
    "mean_iou_metric.update_state(val_masks, val_preds_bin)\n",
    "mean_iou = mean_iou_metric.result().numpy()\n",
    "\n",
    "# Save metrics to Excel\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Precision': [precision],\n",
    "    'F1 Score': [f1],\n",
    "    'Mean IoU': [mean_iou]\n",
    "})\n",
    "print(f\"Precision: \", precision, \"F1 score: \", f1, \"Mean Iou : \", mean_iou)\n",
    "\n",
    "# Plot training history\n",
    "history_df = pd.read_excel('training_history.xlsx')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history_df['loss'], label='Training Loss')\n",
    "plt.plot(history_df['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig('loss_plot.png')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history_df['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history_df['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig('accuracy_plot.png')\n",
    "plt.show()\n",
    "\n",
    "# Save confusion matrix as heatmap\n",
    "cm = confusion_matrix(val_masks.flatten(), val_preds_bin.flatten())\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig('confusion_matrix.png')\n",
    "plt.show()\n",
    "\n",
    "# Visualize some predictions on validation set\n",
    "for i in range(3):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    axs[0].imshow(val_images[i])\n",
    "    axs[0].set_title('Input Image')\n",
    "    axs[1].imshow(val_masks[i].squeeze(), cmap='gray')\n",
    "    axs[1].set_title('Ground Truth')\n",
    "    axs[2].imshow(val_preds_bin[i].squeeze(), cmap='gray')\n",
    "    axs[2].set_title('Predicted Mask')\n",
    "    plt.savefig(f'prediction_{i}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096d9b51-f87c-4e08-8c99-7c829dfb4501",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate inference time\n",
    "\n",
    "# Use a small batch from validation data\n",
    "sample_images = val_images[:5]\n",
    "\n",
    "# Measure inference time\n",
    "start_time = time.time()\n",
    "predictions = model.predict(sample_images)\n",
    "end_time = time.time()\n",
    "\n",
    "inference_time = (end_time - start_time) / len(sample_images)\n",
    "print(f\"Average Inference Time per Image: {inference_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cbca91-f16f-48df-bd29-d3539bf87111",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Define input size\n",
    "input_size = (512, 512, 3)\n",
    "\n",
    "# Function to preprocess images\n",
    "def preprocess_image(image_path, target_size):\n",
    "    # Load image\n",
    "    image = load_img(image_path, target_size=target_size[:2])\n",
    "    # Convert to numpy array\n",
    "    image_array = img_to_array(image)\n",
    "    # Normalize the image\n",
    "    image_array = image_array / 255.0\n",
    "    return image_array\n",
    "\n",
    "# Function to save images\n",
    "def save_image(image_array, save_path):\n",
    "    # Convert array to image\n",
    "    image = array_to_img(image_array)\n",
    "    # Save the image\n",
    "    image.save(save_path)\n",
    "\n",
    "# Function to display images\n",
    "def display_images(images, titles=None, cmap='gray'):\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    for i, image in enumerate(images):\n",
    "        plt.subplot(3, 4, i + 1)  # Adjust depending on the number of images\n",
    "        plt.imshow(image, cmap=cmap)\n",
    "        if titles:\n",
    "            plt.title(titles[i])\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Load and preprocess images\n",
    "image_folder = '/home/syam.varnatt/THESIS/Plot_Images(x10,x20)'\n",
    "image_paths = [os.path.join(image_folder, fname) for fname in os.listdir(image_folder) if fname.endswith('.png')]\n",
    "\n",
    "# Sort the image paths by filenames\n",
    "image_paths = sorted(image_paths)\n",
    "\n",
    "# Select a subset of images\n",
    "image_paths = image_paths[0:]\n",
    "\n",
    "# Predict segmentation masks for each image\n",
    "# Extract image names from paths\n",
    "image_names = [os.path.basename(path) for path in image_paths]\n",
    "\n",
    "# Define the folder path to save images and masks\n",
    "save_folder = '/home/syam.varnatt/THESIS/comparison-model/unet/no-aug/predict_height'\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "# Predict segmentation masks and save images and masks\n",
    "predicted_masks = []\n",
    "for i, image_path in enumerate(image_paths):\n",
    "    # Preprocess image\n",
    "    image = preprocess_image(image_path, input_size)\n",
    "    image_batch = np.expand_dims(image, axis=0)\n",
    "    # Predict mask\n",
    "    predicted_mask = model.predict(image_batch)[0]\n",
    "    predicted_mask = (predicted_mask > 0.5).astype(np.uint8)\n",
    "    \n",
    "    # Save the original image\n",
    "    original_image = img_to_array(load_img(image_path, target_size=input_size[:2])) / 255.0\n",
    "    save_image(original_image, os.path.join(save_folder, f'original_{image_names[i]}'))\n",
    "    \n",
    "    # Save the predicted mask\n",
    "    save_image(predicted_mask, os.path.join(save_folder, f'mask_{image_names[i]}'))\n",
    "    \n",
    "    predicted_masks.append(predicted_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e36e497-2dac-4843-a1cf-6581a0311b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate inference time for predicting heights\n",
    "\n",
    "# Use a small batch from validation data\n",
    "sample_images = image_batch[:5]\n",
    "\n",
    "# Measure inference time\n",
    "start_time = time.time()\n",
    "predictions = model.predict(sample_images)\n",
    "end_time = time.time()\n",
    "\n",
    "inference_time = (end_time - start_time) / len(sample_images)\n",
    "print(f\"Average Inference Time per flight height predicted Image: {inference_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d57ce7-9af9-4953-89af-415c3dd38347",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
